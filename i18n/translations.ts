export const translations = {
  en: {
    'header.title': 'Reinforcement Learning Agent Dashboard',
    'header.subtitle': 'Visualizing Agent Psychology & Q-Learning',
    'controls.start': 'Start',
    'controls.pause': 'Pause',
    'controls.reset': 'Reset',
    'controls.save': 'Save',
    'controls.load': 'Load',
    'controls.speed': 'Speed:',
    'controls.speed.slow': 'Slow',
    'controls.speed.normal': 'Normal',
    'controls.speed.fast': 'Fast',
    'controls.speed.insane': 'Insane',
    'controls.episode': 'Episode:',
    'controls.step': 'Step:',
    'config.title': 'Live Configuration',
    'config.learning_rate': 'Learning Rate (α)',
    'config.discount_factor': 'Discount Factor (γ)',
    'config.exploration': 'Exploration (ε)',
    'config.frustration_threshold': 'Frustration Threshold',
    'config.exploration_boost': 'Impulsive Exploration Boost',
    'config.meta_cognitive_boost': 'Meta-Cognitive Boost',
    'config.enable_obstacles': 'Enable Obstacles',
    'config.num_obstacles': 'Number of Obstacles',
    'performance.title': 'Performance',
    'chart.avg_reward': 'Avg Reward',
    'chart.waiting': 'Waiting for more data...',
    'logs.title': 'Global Logs',
    'logs.export': 'Export Logs',
    'logs.waiting': 'Simulation logs will appear here...',
    'logs.source.system': 'SYSTEM',
    'logs.source.agent': 'AGENT',
    'logs.source.env': 'ENV',
    'logs.source.rule-engine': 'RULE-ENGINE',
    'logs.source.gemini': 'GEMINI',
    'details.title': 'Agent Details',
    'dashboard.initializing': 'Initializing agents...',
    'card.agent': 'Agent',
    'card.reward': 'Reward',
    'card.drives': 'Drives',
    'card.drives.curiosity': 'Curiosity',
    'card.drives.understanding': 'Understanding',
    'card.drives.frustration': 'Frustration',
    'card.q_learning_state': 'Q-Learning State',
    'card.state': 'State',
    'card.q_value_action': 'Act',
    'card.goal': 'Goal',
    'card.subgoal': 'Sub',
    'card.event_history': 'Event History',
    'card.no_events': 'No significant events yet.',
    'card.confused_state': 'Agent is confused and is exploring more to find better strategies.',
    'card.activate_agent': 'Activate Agent',
    'card.deactivate_agent': 'Deactivate Agent',
    'card.explain_button': 'Explain with AI',
    'card.explain_button.title': 'Explain Agent\'s Last Decision with Gemini',
    'card.explain_button.disabled_title': 'Gemini API key not configured. This feature is disabled.',
    'gauge.valence': 'Valence',
    'gauge.arousal': 'Arousal',
    'gauge.dominance': 'Dominance',
    'modal.title': 'Gemini Agent Explanation',
    'modal.loading': 'Generating explanation...',
    'modal.loading_cf': 'Generating counterfactual...',
    'modal.counterfactual_title': 'Counterfactual Analysis',
    'modal.counterfactual_button': 'What if it chose Action {action} instead?',
    'env.agent_goal_title': 'Agent {id} Goal',
    'env.agent_title': 'Agent {id}',
    'env.obstacle_title': 'Dynamic Obstacle',
    'q_action.0': 'Move to Goal',
    'q_action.1': 'Move Randomly',
    'event.goal_change': 'Goal Change',
    'event.impulsive_explore': 'Impulsive Exploration',
    'event.new_state': 'New State Discovered',
    'event.frustration_peak': 'Frustration Peak',
    'event.meta_cognition_active': 'Meta-Cognition: Active',
    'event.meta_cognition_inactive': 'Meta-Cognition: Inactive',
    'gemini.prompt.title': 'You are an expert in reinforcement learning observing a simulation.',
    'gemini.prompt.intro': 'An agent using Q-Learning has just made a decision. Based on the data below, provide a brief, insightful explanation for its choice in simple terms for a student.',
    'gemini.prompt.agent_data': 'Agent Data',
    'gemini.prompt.agent_id': 'Agent ID',
    'gemini.prompt.current_goal': 'Current Goal',
    'gemini.prompt.emotions': 'Emotions',
    'gemini.prompt.emotions.valence': 'Valence (Pleasure)',
    'gemini.prompt.emotions.arousal': 'Arousal (Excitement)',
    'gemini.prompt.emotions.dominance': 'Dominance (Control)',
    'gemini.prompt.drives': 'Drives',
    'gemini.prompt.drives.curiosity': 'Curiosity',
    'gemini.prompt.drives.frustration': 'Frustration',
    'gemini.prompt.state': 'Discretized State',
    'gemini.prompt.decision_data': 'Decision Data',
    'gemini.prompt.q_values': 'Q-Values for this state',
    'gemini.prompt.action_chosen': 'Action Chosen',
    'gemini.prompt.action_chosen_text': 'Action {lastAction} ({actionText})',
    'gemini.prompt.task': 'Your Task',
    'gemini.prompt.task_instruction': 'Explain *why* the agent likely chose this action. Consider its Q-values, but also mention how its current emotions or goals might have influenced the decision (e.g., if it chose a suboptimal action, was it exploring due to high arousal or frustration?). Keep it concise and easy to understand.',
    'gemini.prompt.language_instruction': 'Please write the entire explanation in {lang}.',
    'gemini.prompt.counterfactual.title': 'You are an expert in reinforcement learning performing a counterfactual analysis.',
    'gemini.prompt.counterfactual.task': 'Counterfactual Task',
    'gemini.prompt.counterfactual.task_instruction': 'The agent did NOT choose Action {alternativeAction} ({alternativeActionText}). First, predict the most likely immediate outcome if it HAD chosen that action. Specifically, would the immediate reward likely be better, worse, or similar? And how would the agent\'s frustration level likely change? Second, briefly explain your reasoning by comparing Q-values and considering the agent\'s current state and drives.',
    'goal.explore': 'Explore',
    'goal.reduce-frustration': 'Reduce Frustration',
  },
  de: {
    'header.title': 'Dashboard für Reinforcement-Learning-Agenten',
    'header.subtitle': 'Visualisierung von Agentenpsychologie & Q-Learning',
    'controls.start': 'Start',
    'controls.pause': 'Pause',
    'controls.reset': 'Zurücksetzen',
    'controls.save': 'Speichern',
    'controls.load': 'Laden',
    'controls.speed': 'Tempo:',
    'controls.speed.slow': 'Langsam',
    'controls.speed.normal': 'Normal',
    'controls.speed.fast': 'Schnell',
    'controls.speed.insane': 'Turboschnell',
    'controls.episode': 'Episode:',
    'controls.step': 'Schritt:',
    'config.title': 'Live-Konfiguration',
    'config.learning_rate': 'Lernrate (α)',
    'config.discount_factor': 'Diskontierungsfaktor (γ)',
    'config.exploration': 'Exploration (ε)',
    'config.frustration_threshold': 'Frustrationsschwelle',
    'config.exploration_boost': 'Impulsive Explorationsverstärkung',
    'config.meta_cognitive_boost': 'Meta-kognitive Verstärkung',
    'config.enable_obstacles': 'Hindernisse aktivieren',
    'config.num_obstacles': 'Anzahl Hindernisse',
    'performance.title': 'Leistung',
    'chart.avg_reward': 'Ø Belohnung',
    'chart.waiting': 'Warte auf mehr Daten...',
    'logs.title': 'Globale Logs',
    'logs.export': 'Logs exportieren',
    'logs.waiting': 'Simulations-Logs erscheinen hier...',
    'logs.source.system': 'SYSTEM',
    'logs.source.agent': 'AGENT',
    'logs.source.env': 'UMGEBUNG',
    'logs.source.rule-engine': 'REGELWERK',
    'logs.source.gemini': 'GEMINI',
    'details.title': 'Agenten-Details',
    'dashboard.initializing': 'Initialisiere Agenten...',
    'card.agent': 'Agent',
    'card.reward': 'Belohnung',
    'card.drives': 'Antriebe',
    'card.drives.curiosity': 'Neugier',
    'card.drives.understanding': 'Verständnis',
    'card.drives.frustration': 'Frustration',
    'card.q_learning_state': 'Q-Learning-Zustand',
    'card.state': 'Zustand',
    'card.q_value_action': 'Aktion',
    'card.goal': 'Ziel',
    'card.subgoal': 'Unterziel',
    'card.event_history': 'Ereignisverlauf',
    'card.no_events': 'Noch keine wichtigen Ereignisse.',
    'card.confused_state': 'Agent ist verwirrt und exploriert mehr, um bessere Strategien zu finden.',
    'card.activate_agent': 'Agent aktivieren',
    'card.deactivate_agent': 'Agent deaktivieren',
    'card.explain_button': 'Mit KI erklären',
    'card.explain_button.title': 'Letzte Entscheidung des Agenten mit Gemini erklären',
    'card.explain_button.disabled_title': 'Gemini API-Schlüssel nicht konfiguriert. Diese Funktion ist deaktiviert.',
    'gauge.valence': 'Valenz',
    'gauge.arousal': 'Aktivierung',
    'gauge.dominance': 'Dominanz',
    'modal.title': 'Gemini-Agenten-Erklärung',
    'modal.loading': 'Erklärung wird generiert...',
    'modal.loading_cf': 'Kontrafaktische Analyse wird generiert...',
    'modal.counterfactual_title': 'Kontrafaktische Analyse',
    'modal.counterfactual_button': 'Was wäre, wenn stattdessen Aktion {action} gewählt worden wäre?',
    'env.agent_goal_title': 'Agent {id} Ziel',
    'env.agent_title': 'Agent {id}',
    'env.obstacle_title': 'Dynamisches Hindernis',
    'q_action.0': 'Zum Ziel bewegen',
    'q_action.1': 'Zufällig bewegen',
    'event.goal_change': 'Zielwechsel',
    'event.impulsive_explore': 'Impulsive Erkundung',
    'event.new_state': 'Neuen Zustand entdeckt',
    'event.frustration_peak': 'Frustrationsspitze',
    'event.meta_cognition_active': 'Meta-Kognition: Aktiv',
    'event.meta_cognition_inactive': 'Meta-Kognition: Inaktiv',
    'gemini.prompt.title': 'Sie sind ein Experte für Reinforcement Learning und beobachten eine Simulation.',
    'gemini.prompt.intro': 'Ein Agent, der Q-Learning verwendet, hat gerade eine Entscheidung getroffen. Geben Sie auf der Grundlage der folgenden Daten eine kurze, aufschlussreiche Erklärung für seine Wahl in einfachen Worten für einen Studenten.',
    'gemini.prompt.agent_data': 'Agentendaten',
    'gemini.prompt.agent_id': 'Agenten-ID',
    'gemini.prompt.current_goal': 'Aktuelles Ziel',
    'gemini.prompt.emotions': 'Emotionen',
    'gemini.prompt.emotions.valence': 'Valenz (Freude)',
    'gemini.prompt.emotions.arousal': 'Aktivierung (Aufregung)',
    'gemini.prompt.emotions.dominance': 'Dominanz (Kontrolle)',
    'gemini.prompt.drives': 'Antriebe',
    'gemini.prompt.drives.curiosity': 'Neugier',
    'gemini.prompt.drives.frustration': 'Frustration',
    'gemini.prompt.state': 'Diskretisierter Zustand',
    'gemini.prompt.decision_data': 'Entscheidungsdaten',
    'gemini.prompt.q_values': 'Q-Werte für diesen Zustand',
    'gemini.prompt.action_chosen': 'Gewählte Aktion',
    'gemini.prompt.action_chosen_text': 'Aktion {lastAction} ({actionText})',
    'gemini.prompt.task': 'Ihre Aufgabe',
    'gemini.prompt.task_instruction': 'Erklären Sie, *warum* der Agent diese Aktion wahrscheinlich gewählt hat. Berücksichtigen Sie seine Q-Werte, erwähnen Sie aber auch, wie seine aktuellen Emotionen oder Ziele die Entscheidung beeinflusst haben könnten (z. B. wenn er eine suboptimale Aktion gewählt hat, hat er aufgrund hoher Aktivierung oder Frustration exploriert?). Halten Sie es kurz und leicht verständlich.',
    'gemini.prompt.language_instruction': 'Bitte verfassen Sie die gesamte Erklärung auf {lang}.',
    'gemini.prompt.counterfactual.title': 'Sie sind ein Experte für Reinforcement Learning und führen eine kontrafaktische Analyse durch.',
    'gemini.prompt.counterfactual.task': 'Kontrafaktische Aufgabe',
    'gemini.prompt.counterfactual.task_instruction': 'Der Agent hat Aktion {alternativeAction} ({alternativeActionText}) NICHT gewählt. Sagen Sie zuerst das wahrscheinlichste unmittelbare Ergebnis voraus, wenn er diese Aktion gewählt HÄTTE. Insbesondere, wäre die unmittelbare Belohnung wahrscheinlich besser, schlechter oder ähnlich? Und wie würde sich das Frustrationslevel des Agenten wahrscheinlich ändern? Zweitens, begründen Sie Ihre Antwort kurz, indem Sie die Q-Werte vergleichen und den aktuellen Zustand und die Antriebe des Agenten berücksichtigen.',
    'goal.explore': 'Erkunden',
    'goal.reduce-frustration': 'Frustration reduzieren',
  },
};

export type Language = keyof typeof translations;
export type TranslationKey = keyof (typeof translations)['en'];